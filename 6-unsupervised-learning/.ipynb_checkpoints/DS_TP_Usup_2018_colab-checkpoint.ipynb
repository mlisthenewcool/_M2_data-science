{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tcWzxgHzg6-"
   },
   "source": [
    "# Credit to Dongwoo Kim\n",
    "\n",
    "https://github.com/arongdari/python-topic-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zd205417zq5v"
   },
   "source": [
    "#Colab\n",
    "\n",
    "- monter son drive\n",
    "- copier le dataset cora\n",
    "- copier le code ptm\n",
    "- se deplacer dans le dossier ptm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24057,
     "status": "ok",
     "timestamp": 1539275727532,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "STTbSzY8zo2j",
    "outputId": "1f8a9f74-58d5-44d3-9123-a410ddee1aae"
   },
   "outputs": [],
   "source": [
    "#mount your drive\n",
    "from google.colab import drive\n",
    "drive.mount('drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1963,
     "status": "ok",
     "timestamp": 1539275750541,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "RoRaTzBR13Ap",
    "outputId": "cf5f186e-fe2f-44b1-94f1-1e3326924c9d"
   },
   "outputs": [],
   "source": [
    "#!ls drive/My\\ Drive\n",
    "import os\n",
    "os.chdir('drive/My Drive/PATH_TO/ptm')###################################################\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qUiJFb8s05wz"
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('drive/My\\ Drive/TP3_Usup/ptm')##PATH to ptm\n",
    "#!export PYTHONPATH=\"${PYTHONPATH}:drive/My\\ Drive/TP3_Usup/ptm\"##PATH to ptm###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOFSp3Uszg7L"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Exemple of AuthorTopicModel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ua3faBo_zg7O"
   },
   "source": [
    "\"The Author-Topic Model for Authors and Documents\" by Rosen-Zvi, et al. (UAI 2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "n2imnZZ-zg7P"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import logging\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from ptm import AuthorTopicModel##\n",
    "#from ptm.utils import convert_cnt_to_list, get_top_words##\n",
    "#from utils import convert_cnt_to_list, get_top_words##\n",
    "from utils import convert_cnt_to_list, get_top_words\n",
    "\n",
    "logger = logging.getLogger('AuthorTopicModel')\n",
    "logger.propagate=False\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Smv2rCa-zg7d"
   },
   "source": [
    "## Dataset CORA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpRoemIjzg7f"
   },
   "source": [
    "*Dataset* originel disponible à : https://people.cs.umass.edu/~mccallum/data.html\n",
    "Modifier le path vers le dataset dans votre google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cCY_g0Jdzg7h"
   },
   "outputs": [],
   "source": [
    "doc_ids = pickle.load(open('PATH_TO/data/cora/doc_ids.pkl', 'rb'))\n",
    "doc_cnt = pickle.load(open('PATH_TO/data/cora/doc_cnt.pkl', 'rb'))\n",
    "doc_author = pickle.load(open('PATH_TO/data/cora/doc_authorid.pkl', 'rb'))\n",
    "author_name = pickle.load(open('PATH_TO/data/cora/authorid_authorname.pkl', 'rb'))\n",
    "voca = pickle.load(open('PATH_TO/data/cora/voca.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acxZ9CZyzg7o"
   },
   "source": [
    "### Contenu des structures de données\n",
    "- voca : \n",
    "C'est une liste des mots du vocabulaire de l'ensemble des documents. Les autres structures de données font référence aux indices des ots dans cette liste. \n",
    "- author_name : \n",
    "C'est une liste des auteurs de l'ensemble des documents. Les autres structures de données font référence aux indices des auteurs dans cette liste. \n",
    "- doc_author : \n",
    "C'est une liste de listes (une par document). La liste d'un document contient les indices des auteurs du document \n",
    "- doc_ids : \n",
    "C'est une liste de listes (une par document). La liste d'un document contient les indices des mots apparaissant dans le document \n",
    "- doc_cnt :\n",
    "C'est une liste de listes (une par document). La liste d'un document contient le nombre de fois qu'apparait chaque mot du document tel que spédicifié dans la liste correspondante dans doc_ids \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1539275761767,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "oUJuQL9qzg7q",
    "outputId": "86cc061e-396b-4e72-a5e4-5bfd05be3cc0"
   },
   "outputs": [],
   "source": [
    "print (len(doc_ids))\n",
    "print (len(doc_cnt))\n",
    "print (len(doc_author))\n",
    "print (len(author_name))\n",
    "print (len(voca))\n",
    "print (len(doc_ids[1]))\n",
    "print (doc_ids[1])\n",
    "print (doc_cnt[1])\n",
    "print (doc_author[1])\n",
    "print (voca[1])\n",
    "print (author_name[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1539275765000,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "TX3x9WqZzg7y",
    "outputId": "71bf2a8c-8064-4c2a-bd03-ec47cfdf0db8"
   },
   "outputs": [],
   "source": [
    "corpus = convert_cnt_to_list(doc_ids, doc_cnt)\n",
    "n_doc = len(corpus)\n",
    "n_author = len(author_name)\n",
    "n_voca = len(voca)\n",
    "\n",
    "print (n_doc)\n",
    "print (n_author)\n",
    "print (n_voca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGoYPXUGzg79"
   },
   "source": [
    "La fonction convert_cnt_to_list crée une structure de type liste de listes (une par document). La  liste d'un document contient l'ensemble des mots (des indices de mots) du document, éventuellement avec répétitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1539275767990,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "ztuREbA1zg7_",
    "outputId": "b8c40900-7c2e-4d79-c3f3-a0a34ea0863d"
   },
   "outputs": [],
   "source": [
    "print (corpus[1])\n",
    "print (np.sum(doc_cnt[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TIoxpeGfzg8J"
   },
   "source": [
    "## tf-idf\n",
    "\n",
    "- Le code suivant transforme ces représentations sous la forme TF-IDF (term frequency–inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GzJY4rqGzg8K"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\"\"\"\n",
    "    Code tf-idf transform from a set of sample X\n",
    "    \n",
    "    Step 1 - Compute idf for each word of the vocabulary over the entire set.\n",
    "    Step 2 - Compute tf for each sample\n",
    "    Step 3 - Compute tf times idf to build transformed sample descriptors\n",
    "\"\"\"\n",
    "def tf_idf_transform(corpus, doc_ids, n_doc, n_voca):\n",
    "    t = time.time()\n",
    "    idf = np.zeros(shape=(n_voca,1))\n",
    "    for i in range(n_doc):\n",
    "        for j in range(len(doc_ids[i])):\n",
    "            idf[doc_ids[i][j]] += 1\n",
    "            #break\n",
    "    \n",
    "    idf = np.divide(idf,n_doc)\n",
    "        \n",
    "    zezeros = np.where(idf == 0)[0] \n",
    "    idf[zezeros] = 0.0000000001\n",
    "    \n",
    "    idf = np.divide(1,idf)\n",
    "    idf = np.log(idf)\n",
    "    \n",
    "    elapsed = time.time() - t\n",
    "    print (elapsed)\n",
    "    \n",
    "\n",
    "    t = time.time()\n",
    "    tf = np.zeros(shape=(n_voca,n_doc))\n",
    "    for i in range(n_doc):\n",
    "        #print(i,n_doc)\n",
    "        for j in range(len(corpus[i])):  \n",
    "            tf[corpus[i][j]][i] += 1\n",
    "        tf[:][i] = np.divide(tf[:][i],len(corpus[i]))\n",
    "        \n",
    "#    print(n_doc)\n",
    "#    print(idf.shape)\n",
    "#    print(tf.shape)\n",
    "\n",
    "#    for i in range(n_doc):\n",
    "#        #print(i,n_doc)\n",
    "#        np.multiply(tf[:][i],idf)\n",
    "    for i in range(idf.size):\n",
    "        #print(i,n_doc)\n",
    "        tf[i][:]=np.multiply(tf[i][:],idf[i])\n",
    "                \n",
    "    elapsed = time.time() - t\n",
    "    print (elapsed)  \n",
    "            \n",
    "    return tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "hbpAogYmzg8W"
   },
   "source": [
    "# A faire\n",
    "\n",
    "1. Appliquer la transformation tf-idf aux données\n",
    "\n",
    "2. Utiliser sklearn.cluster.KMeans pour faire le clustering des données.\n",
    "\n",
    "3. Pour 10 clusters: \n",
    "  - afficher les mots les plus fréquents et discriminants (maximums des descripteurs)\n",
    "  - afficher la population de chaque cluster\n",
    "  - calculer une matrice de similarité entre les différents clusters\n",
    "  \n",
    "Note: Une distance de similarité très utilisée est de normaliser l2 les vecteurs et de calculer le dot product entre deux vecteurs pour avoir un cosine similarity (\"inversement\" équivalente à une distance euclidienne dans ce cas la). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PgETNtwm7R-H"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CfDqzqPzg8b"
   },
   "source": [
    "## K-means et bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "6yvrkSJRzg8e"
   },
   "source": [
    "- créer une représentation bag-of-words à partir des descripteurs initiaux\n",
    "- utiliser sklearn.cluster.KMeans pour créer votre codebook (\"vocabulaire\").\n",
    "- observer les résultats: mots les plus fréquents dans les clusters\n",
    "\n",
    "- refaire les clustering après normalisation l2 des descripteurs\n",
    "- observer encore les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Elc5Py-rzg8g"
   },
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "Ae6GVPo8zg8i"
   },
   "source": [
    "import sys\n",
    "sys.path.append(\"/users/usrlocal/artieres/\") \n",
    "#sys.path.append(\"/users/usrlocal/artieres/Cours/Data\\ Science/Code/\")\n",
    "\n",
    "import LatentVariableModels\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47544,
     "status": "ok",
     "timestamp": 1539275907012,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "Xp_yhBECzg8k",
    "outputId": "24e38268-ce20-417e-d2b0-ecd926de5418"
   },
   "outputs": [],
   "source": [
    "#from ptm import GibbsLDA\n",
    "from lda_gibbs import GibbsLDA\n",
    "\n",
    "max_iter=4\n",
    "n_topic=10\n",
    "\n",
    "modelLDA = GibbsLDA(n_doc, len(voca), n_topic)\n",
    "modelLDA.fit(corpus, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ES9YJe_9zg8p"
   },
   "source": [
    "### Les 10 mots les plus probables pour chaque topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1539275946684,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "rbMnl97-zg8r",
    "outputId": "fd871490-a1fa-4d6e-8b94-614e0e7c9fdb"
   },
   "outputs": [],
   "source": [
    "for ti in range(n_topic):\n",
    "    top_words = get_top_words(modelLDA.TW, voca, ti, n_words=10)\n",
    "    print('Topic', ti ,': ', ','.join(top_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OouH1XUzzg8x"
   },
   "source": [
    "##  Modèle author-topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55728,
     "status": "ok",
     "timestamp": 1539276005224,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "CC9TsUeZzg80",
    "outputId": "ec0407db-c041-464d-9bae-cb71d29a64db"
   },
   "outputs": [],
   "source": [
    "from at_model import AuthorTopicModel\n",
    "\n",
    "max_iter=1\n",
    "n_topic=10\n",
    "\n",
    "modelAT = AuthorTopicModel(n_doc, n_voca, n_topic, n_author)\n",
    "\n",
    "modelAT.fit(corpus, doc_author, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pe9ey4Uczg9C"
   },
   "source": [
    "## Les 10 mots les plus probables pour chaque topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1539276028450,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "zJpm0l_vzg9O",
    "outputId": "253c70a2-240f-4f05-b1d9-4fefa684a2a8"
   },
   "outputs": [],
   "source": [
    "for k in range(n_topic):\n",
    "    top_words = get_top_words(modelAT.TW, voca, k, 10)\n",
    "    print('topic ', k , ','.join(top_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykVNTUWIzg9U"
   },
   "source": [
    "## Distribution sur les topics pour un auteur particulier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1539276035166,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "EtexskeOzg9W",
    "outputId": "db698e84-7802-4cac-cc9e-230ed518082f"
   },
   "outputs": [],
   "source": [
    "author_id = 7\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.bar(range(n_topic), modelAT.AT[author_id]/np.sum(modelAT.AT[author_id]))\n",
    "plt.title(author_name[author_id])\n",
    "plt.xticks(np.arange(n_topic)+0.5, ['\\n'.join(get_top_words(modelAT.TW, voca, k, 10)) for k in range(n_topic)])\n",
    "plt.show()\n",
    "modelAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1539276039518,
     "user": {
      "displayName": "ronan sicre",
      "photoUrl": "",
      "userId": "13953710942599121816"
     },
     "user_tz": -120
    },
    "id": "FkNxm_Cpzg9c",
    "outputId": "eb03d741-7506-40d9-b6bd-7d58888d0e51"
   },
   "outputs": [],
   "source": [
    "author_id = 32\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.bar(range(n_topic), modelAT.AT[author_id]/np.sum(modelAT.AT[author_id]))\n",
    "plt.title(author_name[author_id])\n",
    "plt.xticks(np.arange(n_topic)+0.5, ['\\n'.join(get_top_words(modelAT.TW, voca, k, 10)) for k in range(n_topic)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "Nkcbw6GIzg9n"
   },
   "source": [
    "# Travail à faire\n",
    "\n",
    "1. Caractériser les solutions trouvées par les méthodes proposées :\n",
    "    - Définir une mesure de similarité entre topics. \n",
    "    - Calculer le degré de similarité minimmum, maximum et moyen entre deux topics en fonction du nombre d'itérations d'apprentissage de LDA et de AuthorTopic.\n",
    "    - Calculer le degré de similarité minimmum, maximum et moyen entre deux topics en fonction des parametres alpha et beta pour le LDA.\n",
    "    \n",
    "2. Tracer les courbes de ces statistiques des similarités pour plusieurs topics.\n",
    "\n",
    "3. En vous servant des topic models donnez les mot(s) les plus écrits pour un auteur donné (plus fortes probabilités)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_TP_Usup_2018_colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
