{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "306886_Partie2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzCqf6DEvz4g",
        "colab_type": "text"
      },
      "source": [
        "<h1> Examen Data Science 2019-2020 Partie 2</h1>\n",
        "\n",
        "<h2> Tous documents aurotisés - 3 heures </h2>\n",
        "\n",
        "Partie d'examen sur machine, tout documents autorisés. Pour l'anonymisation de votre rendu, veuillez suivre les consignes suivantes : \n",
        "\n",
        "- Choisissez un numéro aléatoire à 6 chiffres, le plus aléatoire possible.. Utilisez le même numéro aléatoire pour les 2 parties\n",
        "- Ecrivez ce numéro ainsi que votre nom et numéro d'étudiant sur la feuille qui circulera en fin d'examen \n",
        "- Zippez votre fichier notebook, et nommez l'archive avec votre numéro aléatoire suivi de \"_Partie2\". Par exempke \"127635_Partie2.ipynb\n",
        "- Envoyez l'archive via la page :  http://stephane.ayache.perso.luminy.univ-amu.fr/examds/upload/upload.php \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1PD38tfb0dW",
        "colab_type": "text"
      },
      "source": [
        "# Learning to rank\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fMrJQPLb5_p",
        "colab_type": "text"
      },
      "source": [
        "## Introduction \n",
        "\n",
        "Le ranking est un problème d'apprentissage différent de la classification ou de la régression, qui consiste à apprendre à ordonner un ensemble d'exemples. \n",
        "\n",
        "Un cadre d'application classique est la Recherche d'Information. Un moteur de recherche a pour but de donner un score (de pertinence) à chaque document parmi un ensemble de documents (e.g. les pages du web) pour une requête donnée. Ces scores sont ensuite utilisés pour construire le résultat du moteur de recherche en ordonnant les documents par score de pertinence décroissant. Un moteur de recherche est appris sur un ensemble de requêtes d'apprentissage où un ensemble de documents (éventuellement différent pour chaque requête) est fourni pour chaque requête, avec des scores associés correpesdnant à la pertinence de chaque document pour la requête.\n",
        "\n",
        "Plus généralement, l'apprentissage d'un modèle (linéaire) de ranking est  formalisé comme suit:\n",
        "* On considère un ensemble de données d'apprentissage  correspondant à $Q$ requêtes avec, pour chacune des requêtes (par exemple la requête numéro $i$), $N$ exemples associés (par exemple des documents) notés $(x^i_j)_{j=1..N}$ ($x^i_j \\in \\mathbb{R}^d$ est le $j^{ieme}$ exemple pour la requête $i$) avec leur scores (de pertinence) associés $y^i_j$ (réels ou entiers, une valeur plus grande indiquant une plus grande pertinence). L'ensemble d'apprentissage est noté (en supposant pour simplifier un même nombre de documents, $N$, pour chaque requête mais ce n'est pas obligatoire):\n",
        " $$T =\\{(x^i_j,y^i_j), i \\in [1..Q], j \\in [1..N]\\}$$ \n",
        "* Pour information, mais ce n'est pas important pour la suite, en réalité $x^i_j$ ne correspond pas à un exemple (e.g. un document) mais à un vecteur de caractéristiques joint calculé à partir de cet exemle et de la requête pour laquelle il est considéré.\n",
        "* Le ranking consiste à apprendre un vecteur de paramètres $w$ à partir de l'ensemble $T$ tel que: $$\\forall i \\in [1..Q], \\forall (j,k) \\in [1..N]^2, y^i_j \\geq y^i_k \\Rightarrow w^T. x^i_j \\geq w^T  x^i_k$$\n",
        "Ce qui compte c'est que les N exemples corrspondant  une même requête soient scorés par le modèle dans l'ordre de leurs pertinences. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUbs5IjtfgOE",
        "colab_type": "text"
      },
      "source": [
        "### Montage de votre drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yfzM90Cfeva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cc143ef5-ee06-4d69-8dba-43e2aa0b9730"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R07teYHkftVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mettez le chemin vers les jeux de données TrainRanking.pickle et TestRanking.pickle \n",
        "\n",
        "os.chdir(\"drive/My Drive/univ/master-2/data-science/exam/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwKuelKgcQnh",
        "colab_type": "text"
      },
      "source": [
        "## Chargement de jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SSb84IHb0dY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b7990052-2f54-47c4-81a6-a0c61753c790"
      },
      "source": [
        "%matplotlib inline\n",
        "from os.path import expanduser, join\n",
        "from time import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOm07oEzSkOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('TrainRanking.pickle', 'rb') as f:\n",
        "    X_train, y_train, qid_train = pickle.load(f)\n",
        "\n",
        "with open('TestRanking.pickle', 'rb') as f:\n",
        "    X_test, y_test, qid_test = pickle.load( f) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BGTMBHfU_2T",
        "colab_type": "text"
      },
      "source": [
        "### Examinez le dataset.\n",
        "Il est constitué de trois matrices, une matrice de train, les $x^i_j$, un vecteur des pertinences des $x$, les $y^i_j$ qui sont les pertinences des $x^i_j$, et un vecteur des requêtes puisque l'on dispose de multiples $x^i_j$ pour une même requête $i$.\n",
        "\n",
        "\n",
        "* Combien y-a-t-il d'exemples ?\n",
        "* Combien y-a-t-il de requêtes?\n",
        "* Combien y a-t-il de documents par requête en moyenne ? \n",
        "* Quelles sont les valeurs min et max de pertinence ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkmCcEomb8Wt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b9e1a5aa-8b87-47ab-c675-c3077ac319c5"
      },
      "source": [
        "print(f'xtrain {X_train.shape}')\n",
        "print(f'ytrain {y_train.shape}')\n",
        "print(f'qidtrain {qid_train.shape}')\n",
        "\n",
        "print(f'xtest {X_test.shape}')\n",
        "print(f'ytest {y_test.shape}')\n",
        "print(f'qidtest {qid_test.shape}')\n",
        "\n",
        "min_pertinence, max_pertinence = 0, 0\n",
        "\n",
        "for x in X_train:\n",
        "    min_x, max_x = np.min(x), np.max(x)\n",
        "    if min_x < min_pertinence:\n",
        "        min_pertinence = min_x\n",
        "    if max_x > max_pertinence:\n",
        "        max_pertinence = max_x\n",
        "\n",
        "print(min_pertinence, max_pertinence)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xtrain (10134, 136)\n",
            "ytrain (10134,)\n",
            "qidtrain (10134,)\n",
            "xtest (24021, 136)\n",
            "ytest (24021, 1)\n",
            "qidtest (24021, 1)\n",
            "-60.3717 65909672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1w0mlsEeHN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80e75abe-db98-4bed-b063-3959d41015f5"
      },
      "source": [
        "10134/136"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74.51470588235294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo-OjNjWclqF",
        "colab_type": "text"
      },
      "source": [
        "### Résultats donnés pour le train \n",
        "\n",
        "* 10134 train\n",
        "* 136 requêtes\n",
        "* 10134/136 = 74.51 documents par requête\n",
        "* -60.3717 min pertinence\n",
        "* 65909672.0 max pertinence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQokjz3Vb0eQ",
        "colab_type": "text"
      },
      "source": [
        "### Mesure de performance NDCG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81INteU1b0eR",
        "colab_type": "text"
      },
      "source": [
        "* Le NDCG est une mesure dévaluation standard pour les problèmes de ranking\n",
        "\n",
        "* Vous trouverez une définition du critère NDCG ici : https://en.wikipedia.org/wiki/Discounted_cumulative_gain et une implémentation ci-dessous.\n",
        "\n",
        "\n",
        "Ces mesures utilisent un vecteur des scores de pertinence, en anglais pertinence = relevance) attribués par la méthode pour chacun des éléments associés à une requête donnée et calculent un score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8BEsJl3b0eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dcg(relevances, rank=10):\n",
        "    \"\"\"Discounted cumulative gain at rank (DCG)\"\"\"\n",
        "    relevances = np.asarray(relevances)[:rank]\n",
        "    n_relevances = len(relevances)\n",
        "    if n_relevances == 0:\n",
        "        return 0.\n",
        "\n",
        "    discounts = np.log2(np.arange(n_relevances) + 2)\n",
        "    return np.sum(relevances / discounts)\n",
        " \n",
        "def ndcg(relevances, rank=10):\n",
        "    \"\"\"Normalized discounted cumulative gain (NDGC)\"\"\"\n",
        "    best_dcg = dcg(sorted(relevances, reverse=True), rank)\n",
        "    if best_dcg == 0:\n",
        "        return 0.\n",
        "\n",
        "    return dcg(relevances, rank) / best_dcg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scXFvatTb0ek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5620d5a7-c597-4d98-f085-d8cdc4721d61"
      },
      "source": [
        "def mean_ndcg(y_true, y_pred, query_ids, rank=10):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    query_ids = np.asarray(query_ids)\n",
        "    # assume query_ids are sorted\n",
        "    ndcg_scores = []\n",
        "    previous_qid = query_ids[0]\n",
        "    previous_loc = 0\n",
        "    for loc, qid in enumerate(query_ids):\n",
        "        if previous_qid != qid:\n",
        "            chunk = slice(previous_loc, loc)\n",
        "            ranked_relevances = y_true[chunk][np.argsort(y_pred[chunk])[::-1]]\n",
        "            ndcg_scores.append(ndcg(ranked_relevances, rank=rank))\n",
        "            previous_loc = loc\n",
        "        previous_qid = qid\n",
        "\n",
        "    chunk = slice(previous_loc, loc + 1)\n",
        "    ranked_relevances = y_true[chunk][np.argsort(y_pred[chunk])[::-1]]\n",
        "    ndcg_scores.append(ndcg(ranked_relevances, rank=rank))\n",
        "    return np.mean(ndcg_scores)\n",
        "\n",
        "mean_ndcg([4, 3, 1, 4, 3], [4, 0, 1, 4, 2], [0, 0, 0, 2, 2], rank=10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9795191506818377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yJvRjzdb0em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_evaluation(model, X, y, qid):\n",
        "    tic = time()\n",
        "    y_predicted = model.predict(X)\n",
        "    prediction_time = time() - tic\n",
        "    print(\"Prediction time: {:.3f}s\".format(prediction_time))\n",
        "    print(\"NDCG@5 score: {:.3f}\".format(\n",
        "    mean_ndcg(y, y_predicted, qid, rank=5)))\n",
        "    print(\"NDCG@10 score: {:.3f}\".format(\n",
        "    mean_ndcg(y, y_predicted, qid, rank=10)))\n",
        "    print(\"NDCG score: {:.3f}\".format(\n",
        "    mean_ndcg(y, y_predicted, qid, rank=None)))\n",
        "    print(\"R2 score: {:.3f}\".format(r2_score(y, y_predicted)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PG7cgGKTRQX",
        "colab_type": "text"
      },
      "source": [
        "#### Analyse des mesures de performance\n",
        "\n",
        "\n",
        "* Que vaut-il mieux, un *NDCG* grand ou petit ?\n",
        "* Quel est le rôle du paramètre *rank* de la fonction *ndcg* ?\n",
        "* Le *NDCG* est il invariant par translation et scaling du vecteur de scores ? Justifiez la réponse.\n",
        "* Que fait la fonction *mean_ndcg* ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS9jtTwRfhNW",
        "colab_type": "text"
      },
      "source": [
        "* un NDCG grand (1 score parfait)\n",
        "* le rank permet de ne considérer que les documents les plus relevants\n",
        "* \n",
        "* la fonction mean_ndcg calcule le ndcg moyen pour un ensemble de prédictions en ne considérant que les `rank` meilleurs documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEveQqEFdQvk",
        "colab_type": "text"
      },
      "source": [
        "## Comparaison de méthodes de ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nuA9jbJbwUf",
        "colab_type": "text"
      },
      "source": [
        "### Sélection de sous ensembles des données d'apprentissage et de test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ow5Di1W7t6",
        "colab_type": "text"
      },
      "source": [
        "Afin de pouvoir expérimenter certaines des méthodes ci dessous il faut limiter la taille des données. Ce que font les méthodes suivantes en ne considérant qu'un nombre limité des requêtes en train et en test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9yPMda28bm9Z",
        "colab": {}
      },
      "source": [
        "Nqueries_train = 50\n",
        "Nqueries_test = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rx_WHSHPbm9R",
        "colab": {}
      },
      "source": [
        "def subsample(X, y, qid, size, seed=None):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    unique_qid = np.unique(qid)\n",
        "    qid_mask = rng.permutation(len(unique_qid))[:size]\n",
        "    subset_mask = np.in1d(qid, unique_qid[qid_mask])\n",
        "    print(subset_mask)\n",
        "    a =  y[subset_mask]\n",
        "    return X[subset_mask,:],a, qid[subset_mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEJ9VsK9bm9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "770a761c-9118-4a7d-ca02-04ae330bc3d8"
      },
      "source": [
        "X_train_small, y_train_small, qid_train_small = subsample(\n",
        "    X_train, y_train, qid_train, Nqueries_train, seed=0)\n",
        "print (X_train.shape, X_train_small.shape, y_train.shape, y_train_small.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False ... False False False]\n",
            "(10134, 136) (2085, 136) (10134,) (2085,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "avIY1JPUbm84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a475447-86de-4809-e78d-d88629b951b9"
      },
      "source": [
        "X_test_small, y_test_small, qid_test_small = subsample(\n",
        "    X_test, y_test, qid_test, Nqueries_test, seed=0)\n",
        "print (X_test.shape, X_test_small.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False ... False False False]\n",
            "(24021, 136) (5449, 136)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877nmpu5b0fQ",
        "colab_type": "text"
      },
      "source": [
        "### Une première méthode simple pour le ranking: la régression linéaire\n",
        "\n",
        "* Vous utiliserez ici une première méthode pour le problème de ranking qui consiste en une méthode simple de régression linéaire visant à prédire la valeur de pertinence $y$ à partir de l'élement $x$, en apprenant sur l'ensemble des données de toutes les requêtes.\n",
        "\n",
        "* Mettez en oeuvre cette méthode et calculez en la performance.\n",
        "* Vous évaluerez s'il y a overfitting en calculant les performances en train et en test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsGNOGgmdI-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "835b6aba-22ae-4cd0-eb8c-70e84af30117"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "clf_ols = LinearRegression()\n",
        "clf_ols.fit(X_train, y_train)\n",
        "print('--- ON TRAIN ---')\n",
        "print_evaluation(clf_ols, X_train, y_train, qid_train)\n",
        "\n",
        "print('--- ON TEST ---')\n",
        "print_evaluation(clf_ols, X_test, y_test, qid_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- ON TRAIN ---\n",
            "Prediction time: 0.009s\n",
            "NDCG@5 score: 0.567\n",
            "NDCG@10 score: 0.592\n",
            "NDCG score: 0.775\n",
            "R2 score: 0.200\n",
            "--- ON TEST ---\n",
            "Prediction time: 0.008s\n",
            "NDCG@5 score: 0.419\n",
            "NDCG@10 score: 0.438\n",
            "NDCG score: 0.960\n",
            "R2 score: -2.955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fvYtqGCjNQk",
        "colab_type": "text"
      },
      "source": [
        "**conclusions**\n",
        "\n",
        "* il semblerait que l'algorithme fonctione très bien lorsqu'on ne fixe pas de rang.\n",
        "\n",
        "* si un rang est fixé, alors on est clairement en sur-apprentissage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuKqBup4b0fk",
        "colab_type": "text"
      },
      "source": [
        "### Une deuxième méthode basée sur les SVMs : SVMrank\n",
        "\n",
        "SVMRank est une méthode de ranking inspirée du formalisme des SVMs. SVMRank vise à se ramener à l'apprentissage d'un SVM pour la classification binaire. L'algorithme fonctionne comme suit:\n",
        "\n",
        "* On construit une nouvelle base d'apprentissage à partir de toutes les paires d'exemples (uniquement les paires d'exemples correspondant à une même requête et à des scores de pertinence différents) en calculant la différence entre les exemples de la paire, c'est à dire que l'on calcule $ \\forall i \\in Q, \\forall j,k \\in [1..N]^2, (x^i_j- x^i_k)$, qui constituent les exemples de cette base d'apprentissage. Pour chaque nouvel exemple de cette base (e.g. $(x^i_j- x^i_k)$) la classe à prédire est $1$ si $y^i_j \\geq y^i_k$  et elle est égale à $-1$ sinon.  \n",
        "\n",
        "* On apprend un SVM (on ne considérera que des SVMs linéaires ici) à classifier cette nouvelle base d'apprentissage, ce qui produit un vecteur de paramètres $w$ après apprentissage. A noter, le score de pertinence produit pour une entrée $x^i_j$ par le modèle est donné par $w^T x^i_j$. \n",
        "\n",
        "* En inférence, pour une requête donnée on calcule le score de tous les exemples associés à la requête (ce sont les scores prédits de pertinence de ces exemples) et on calcule un NDCG.\n",
        "\n",
        "1. En vous inspirant par exemple du code ici : https://gist.github.com/coreylynch/4150976/1a2983d3a896f4caba33e1a406a5c48962e606c0\n",
        " * Programmez SVMRank en utilisant comme classifieur binaire *sklearn.linear_model.SGDClassifier* \n",
        " * Evaluez SVMRank sur les données et comparez ses performances à la baseline. Vous pourrez utiliser *decision_function* pour calculer les scores de pertinence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbqOgAO-jsZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def transform_pairwise(X, y):\n",
        "    \"\"\"Transforms data into pairs with balanced labels for ranking\n",
        "    Transforms a n-class ranking problem into a two-class classification\n",
        "    problem. Subclasses implementing particular strategies for choosing\n",
        "    pairs should override this method.\n",
        "    In this method, all pairs are choosen, except for those that have the\n",
        "    same target value. The output is an array of balanced classes, i.e.\n",
        "    there are the same number of -1 as +1\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (n_samples, n_features)\n",
        "        The data\n",
        "    y : array, shape (n_samples,) or (n_samples, 2)\n",
        "        Target labels. If it's a 2D array, the second column represents\n",
        "        the grouping of samples, i.e., samples with different groups will\n",
        "        not be considered.\n",
        "    Returns\n",
        "    -------\n",
        "    X_trans : array, shape (k, n_feaures)\n",
        "        Data as pairs\n",
        "    y_trans : array, shape (k,)\n",
        "        Output class labels, where classes have values {-1, +1}\n",
        "    \"\"\"\n",
        "    X_new = []\n",
        "    y_new = []\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 1:\n",
        "        y = np.c_[y, np.ones(y.shape[0])]\n",
        "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
        "    for k, (i, j) in enumerate(comb):\n",
        "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
        "            # skip if same target or different group\n",
        "            continue\n",
        "        X_new.append(X[i] - X[j])\n",
        "        y_new.append(np.sign(y[i, 0] - y[j, 0]))\n",
        "        # output balanced classes\n",
        "        if y_new[-1] != (-1) ** k:\n",
        "            y_new[-1] = - y_new[-1]\n",
        "            X_new[-1] = - X_new[-1]\n",
        "    return np.asarray(X_new), np.asarray(y_new).ravel()\n",
        "\n",
        "\n",
        "class RankSVM(SGDClassifier):\n",
        "    \"\"\"Performs pairwise ranking with an underlying SGDClassifer model\n",
        "    Input should be a n-class ranking problem, this object will convert it\n",
        "    into a two-class classification problem, a setting known as\n",
        "    `pairwise ranking`.\n",
        "    Authors: Fabian Pedregosa <fabian@fseoane.net>\n",
        "             Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
        "    https://gist.github.com/2071994\n",
        "    \"\"\"\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit a pairwise ranking model.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array, shape (n_samples, n_features)\n",
        "        y : array, shape (n_samples,) or (n_samples, 2)\n",
        "        Returns\n",
        "        -------\n",
        "        self\n",
        "        \"\"\"\n",
        "        X_trans, y_trans = transform_pairwise(X, y)\n",
        "        super(RankSVM, self).fit(X_trans, y_trans)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred = super(RankSVM, self).predict(X)\n",
        "        # preds are mapped to {-1,1}\n",
        "        # FIXME only works in this example!!!\n",
        "        pred[pred == -1] = 0\n",
        "        return pred\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Because we transformed into a pairwise problem, chance level is at 0.5\n",
        "        \"\"\"\n",
        "        X_trans, y_trans = transform_pairwise(X, y)\n",
        "        return np.mean(super(RankSVM, self).predict(X_trans) == y_trans)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A94PfjbBj9wE",
        "colab_type": "text"
      },
      "source": [
        "2. Les scores NDCG obtenus sont-ils comparables avec ceux obtenus avec la régression linéaire ? Est-ce normal ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-K8UbNPjtnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "d9e59dd9-c1a0-4552-a7fb-1909f022cbf8"
      },
      "source": [
        "clf_ols = LinearRegression()\n",
        "clf_ols.fit(X_train_small, y_train_small)\n",
        "print('--- OLS ON TRAIN ---')\n",
        "print_evaluation(clf_ols, X_train_small, y_train_small, qid_train_small)\n",
        "\n",
        "print('--- OLS ON TEST ---')\n",
        "print_evaluation(clf_ols, X_test_small, y_test_small, qid_test_small)\n",
        "\n",
        "clf_svm = RankSVM()\n",
        "clf_svm.fit(X_train_small, y_train_small)\n",
        "print('--- SVM ON TRAIN ---')\n",
        "print_evaluation(clf_svm, X_train_small, y_train_small, qid_train_small)\n",
        "\n",
        "print('--- SVM ON TEST ---')\n",
        "print_evaluation(clf_svm, X_test_small, y_test_small, qid_test_small)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- OLS ON TRAIN ---\n",
            "Prediction time: 0.001s\n",
            "NDCG@5 score: 0.650\n",
            "NDCG@10 score: 0.687\n",
            "NDCG score: 0.810\n",
            "R2 score: 0.339\n",
            "--- OLS ON TEST ---\n",
            "Prediction time: 0.002s\n",
            "NDCG@5 score: 0.399\n",
            "NDCG@10 score: 0.437\n",
            "NDCG score: 0.940\n",
            "R2 score: -0.870\n",
            "--- SVM ON TRAIN ---\n",
            "Prediction time: 0.002s\n",
            "NDCG@5 score: 0.431\n",
            "NDCG@10 score: 0.475\n",
            "NDCG score: 0.700\n",
            "R2 score: -0.028\n",
            "--- SVM ON TEST ---\n",
            "Prediction time: 0.009s\n",
            "NDCG@5 score: 0.311\n",
            "NDCG@10 score: 0.346\n",
            "NDCG score: 0.940\n",
            "R2 score: -0.029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMf90HYRmsdC",
        "colab_type": "text"
      },
      "source": [
        "**conclusion**\n",
        "\n",
        "* SVMRank donne des scores comparables à la régression linéaire bien que légèrement en dessous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "723GqJtYmkJr",
        "colab_type": "text"
      },
      "source": [
        "3. La corrélation de rang de speramn ou le taux de corrélation de Kendall sont peut-être plus adaptés. Voir les liens  https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient et  https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient. \n",
        " * Qu'en pensez vous ? \n",
        " * kendall tau peut-être utilisé via un import *from scipy import stats* puis *stats.kendalltau*. Donne-t-il des résultats plus satisfaisants ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C62ljlmkGn_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1eb73a2c-4a08-4457-d71a-8f738d61a137"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "svm_preds = clf_svm.predict(X_test_small)\n",
        "svm_tau, svm_p_value = stats.kendalltau(y_test_small, svm_preds)\n",
        "print(f'kendall correlation for SVM {svm_tau}')\n",
        "\n",
        "ols_preds = clf_ols.predict(X_test_small)\n",
        "ols_tau, ols_p_value = stats.kendalltau(y_test_small, ols_preds)\n",
        "print(f'kendall correlation for OLS {ols_tau}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kendall correlation for SVM 0.24264534451999034\n",
            "kendall correlation for OLS 0.27542987225634424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hpxIKZEn-Sb",
        "colab_type": "text"
      },
      "source": [
        "**conclusion**\n",
        "\n",
        "* la corrélation de Kendall semble intéressante pour des données temporelles ou périodiques puisqu'elle permet de dire que des paires de prédiction sont correctes si elles sont numériquement bien placées $(x_i, y_i) < (x_j, y_j)$ ou $(x_i, y_i) > (x_j, y_j)$\n",
        "\n",
        "* je n'ai pas le temps de vérifier s'il donne des résultats plus satisfaisants dans ce cas donné, il faudrait pour ça analyser les requêtes et documents associés pour vérifier dans quelle mesure telle ou telle métrique est adaptée : ça n'a pas vraiment de sens d'en parler sans regarder les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDN7-YMvpRqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}