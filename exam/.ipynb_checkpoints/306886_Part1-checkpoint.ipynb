{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "306886_Part1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4uq0Mq2yT3c",
        "colab_type": "text"
      },
      "source": [
        "<h1> Examen Data Science 2019-2020 Partie 1</h1>\n",
        "\n",
        "<h2> Tous documents aurotisés - 3 heures </h2>\n",
        "\n",
        "\n",
        "Partie d'examen sur machine, tout documents autorisés. Pour l'anonymisation de votre rendu, veuillez suivre les consignes suivantes : \n",
        "\n",
        "- Choisissez un numéro aléatoire à 6 chiffres, le plus aléatoire possible.. Utilisez le même numéro aléatoire pour les 2 parties\n",
        "- Ecrivez ce numéro ainsi que votre nom et numéro d'étudiant sur la feuille qui circulera en fin d'examen \n",
        "- Zippez votre fichier notebook, et nommez l'archive avec votre numéro aléatoire suivi de \"_Partie1\". Par exempke \"127635_Partie1.ipynb\n",
        "- Envoyez l'archive via la page :  http://stephane.ayache.perso.luminy.univ-amu.fr/examds/upload/upload.php \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6YH2L61SDyh",
        "colab_type": "text"
      },
      "source": [
        "# Prédiction Structrée\n",
        "\n",
        "Dans cette exercice, nous nous intéressons au problème de la prédiction structurée. L'objectif est d'étudier des algorithmes basés sur une approche de régression pour la prédicition strucutrée. \n",
        "\n",
        "* Le problème de prédiction structurée dans le cas d'apprentissage supervisé revient à apprendre une fonction de prédiction à partir d'exemples annotés $\\{(x_i,y_i), i=1,\\ldots,n\\}$ avec la particularité que les étiquettes $y_i$ sont dans ce cas des données complexes structurées et non pas des vecteurs réels comme pour la classification et la régression.\n",
        "\n",
        "* Un point important dans ce cas est que les données de sortie présentent une structure à prendre en compte pendant la phase d'apprentissage afin que la prédiction puisse permettre de produire des données qui respectent cette structure. Par exemple, en bio-informatique le problème de prédiction de réseaux d’interactions entre gènes peut être considéré comme un problème de prédiction structurée dans laquelle l'ensemble possible des sorties structurées est l'ensemble de tous les graphes modélisant les interactions possibles.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSQY9W_5VsCg",
        "colab_type": "text"
      },
      "source": [
        "Dans cet exercice nous allons considérer le jeu de données `digits`, disponible en utilisant la commande\n",
        "`from sklearn.datasets import load_digits`, et les méthodes d'apprentissage suivantes :\n",
        "\n",
        "*   régression par moindres carrés,\n",
        "*   régression linéaire de faible rang,\n",
        "*   régression à noyaux sur les entrées.\n",
        "\n",
        "L'objectif ici est de prédire la moitié inférieure d'une image à partir de sa moitié supérieure (voir figure ci-dessous).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s489xjL--VYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# core libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# data libraries\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# plot libraries\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mhAH8rhfNJn",
        "colab_type": "code",
        "outputId": "4bbb5031-95c6-408b-b4df-9ba5d87f0759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "digits = load_digits()\n",
        "images = digits.data\n",
        "\n",
        "IMG_LENGTH = int(np.sqrt(images[0, :].shape))\n",
        "\n",
        "print(image.shape)\n",
        "\n",
        "image = np.reshape(image, (IMG_LENGTH, IMG_LENGTH))\n",
        "x = image[0:IMG_LENGTH//2, :]\n",
        "y = image[IMG_LENGTH//2:, :]\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.title('image')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(x, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.title('moitié supérieure')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(y, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.title('moitié inférieure')\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAACRCAYAAAAFOJmzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAmZgpUH7B9Z",
        "colab_type": "text"
      },
      "source": [
        "## Partie 1 : régression de faible rang\n",
        "\n",
        "On considère ici la régression linéaire pour prédire la moitié inférieure des images. Une façon de prendre en compte la structure des sorties est d'ajouter une régularisation sur le rang de la matrice de prédiction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c54tgP3k7x9N",
        "colab_type": "text"
      },
      "source": [
        "1) Soit le problème de régression de faible rang avec une régularisation L2 défini comme suit :\n",
        "$\\min_W \\sum_i \\|y_i - W x_i\\|^2 \\quad s.t. \\quad rank(W) \\leq r$,\n",
        "avec $x_i \\in \\mathbb{R}^d$, $y_i \\in \\mathbb{R}^p$, $W \\in \\mathbb{R}^{p\\times d}$ et $r$ un hyperparamètre reprsentant une contrainte sur le rang de $W$.\n",
        "\n",
        "Expliquer les différentes étapes permettant de résoudre ce problème.\n",
        "\n",
        "Quelle est la complexité calculatoire de la solution ?\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAA51LZUAxOP",
        "colab_type": "text"
      },
      "source": [
        "*Réponse ici*\n",
        "\n",
        "\n",
        "*   étape 1 : effectuer une régression OLS (Ordinary Least Square) classique (avec une régularisation L2 si nécessaire dans ce cas particulier)\n",
        "\n",
        "* étape 2 : décomposer la matrice ($XW$) en valeurs singulières (SVD en anglais) t.q. l'on obtienne $U \\Sigma V$ trois matrices, celle qui nous intéresse ici est la matrice $V$ qui contient un ensemble de vecteurs de base orthonormés.\n",
        "\n",
        "* étape 3 : utiliser ce $V$ et calculer le produit scalaire entre $W$ et $(transpose(V[:r]) \\ @ \\ V[:r])$ où $r$ est l'hyperparamètre de notre régression\n",
        "\n",
        "*   la complexité calculatoire dépend de la dimension des données et de la décomposition, donc : \n",
        "    * $O(p²d)$ pour OLS\n",
        "    * **TODO**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcVV7DP_A4Ls",
        "colab_type": "text"
      },
      "source": [
        "2) Implémenter  l'algorithme de régression de faible rang.\n",
        "\n",
        "* Remarque : dans le cas des données digits, d et p sont respectivement les nombres de pixels de la moitié supérieure (donnée d'entrée) et inférieure (données de sortie) des images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN90pwNRCNXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7fb16b58-7e7c-4d2c-ebba-3fc468d5d8d3"
      },
      "source": [
        "def split_upper_down_parts_for_one_image(image):\n",
        "    x = image[0:IMG_LENGTH//2, :]\n",
        "    y = image[IMG_LENGTH//2:, :]\n",
        "    return x.flatten(), y.flatten()\n",
        "\n",
        "def split_upper_down_parts(images):\n",
        "    X, Y = [], []\n",
        "\n",
        "    for image in images:\n",
        "        image = np.reshape(image, (IMG_LENGTH, IMG_LENGTH))\n",
        "        x, y = split_upper_down_parts_for_one_image(image)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "X, Y = split_upper_down_parts(images)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797, 32)\n",
            "(1797, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmyIqriuDucK",
        "colab_type": "text"
      },
      "source": [
        "* OLS et LR algorithmes\n",
        "\n",
        "**erreur de matrice singulière en utilisant np.linalg.inv : résultats probablement faussés**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcku-lnJ9ywO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ols_regression(data, target):\n",
        "    #return np.linalg.lstsq(data, target)\n",
        "    #return np.linalg.inv(data.T @ data) @ data.T @ target\n",
        "    return np.linalg.pinv(data.T @ data) @ data.T @ target\n",
        "\n",
        "def lr_regression(data, target, rank):\n",
        "    # ordinary least square regression\n",
        "    weights = ols_regression(data, target)\n",
        "\n",
        "    # svd decomposition\n",
        "    _, _, v = np.linalg.svd(data @ weights)\n",
        "\n",
        "    # we will keep only the `rank` best singular values\n",
        "    best_v = v[:rank].T @ v[:rank]\n",
        "\n",
        "    return weights @ best_v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ePsW3SPF1Mz",
        "colab_type": "text"
      },
      "source": [
        "3) On considère maintenant le problème de régression de faible rang avec une régularisation L2 : \n",
        "$\\min_W \\sum_i \\|y_i - W x_i\\|^2 + \\lambda \\|W\\|^2 \\quad s.t. \\quad rank(W) \\leq r$.\n",
        "\n",
        "Proposer une solution permettant de résoudre ce problème à partir de celle de la régression de faible rang (sans régularisation L2). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmCvaERnGvnj",
        "colab_type": "text"
      },
      "source": [
        "*Réponses ici*\n",
        "\n",
        "* il est possible de considérer deux matrices $A$ et $B$ où $A \\in \\mathbb{R}^{d\\times s}$ et $B \\in \\mathbb{R}^{s\\times k}$ et de considérer la LR-L2 suivante :\n",
        "\n",
        "$$\\min_W \\sum_i \\|y_i - AB x_i\\|^2 + \\lambda \\|AB\\|^2 \\quad$$ \n",
        "\n",
        "* avec $\\quad rank(W) \\leq r$\n",
        "* et $s < min(r, k)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHJ0wYJr_sPY",
        "colab_type": "text"
      },
      "source": [
        "## Partie 2 : régression à noyau sur les entrées\n",
        "\n",
        "La régression de faible rang ci-dessus considère une relation linéaire entre les données d'entrée et de sortie. Afin de remédier à ce problème, on considère maintenant une régression à noyau. Il s'agit de définir une fonction (nonlinéaire) noyau sur les entrées, notée $k$, qui permet de projeter les données dans un espace de plus grande dimension dans lequel une solution linéaire peut êêtre obtenue. \n",
        "\n",
        "Le noyau $k$ permet de calculer le produit scalaire entre les données après un plongement nonlinéaire $\\phi$, c.a.d $k(x_1,x_2) = \\langle \\phi(x1), \\phi(x2) \\rangle$, sans qu'il soit nécessaire de connaître explicitement $\\phi$.\n",
        "\n",
        "La matrice noyau $K$ est la matrice calculée à partir de la fonction noyau appliquée à toutes les paires de données d'apprentissage, c.a.d $K = (k(x_i,x_j))_{i,j=1,\\ldots,n}$. La matrice K est une matrice semi-définie positive de taille $n \\times n$ où $n$ est le nombre de données d'apprentissage, c.a.d, $K$ est symmétrique ($K^\\top = K$) et $\\langle Kz,z\\rangle \\geq 0 \\  \\forall z\\in\\mathbb{R^n}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ9EQ-B4HGAt",
        "colab_type": "text"
      },
      "source": [
        "On peut montrer que le problème de regression à noyau avec une régularisation L2 peut s'écrire comme suit : \n",
        "\n",
        "$\\min_C \\|Y - K C\\|^2 + \\lambda \\langle KC, C\\rangle$,\n",
        "\n",
        "avec $Y\\in \\mathbb{R}^{n\\times p}$ la matrice contenant toutes les sorties vectorielles $y_i$, K la matrice noyau définie ci-dessus, $C\\in \\mathbb{R}^{n*p}$ la matrice de paramètres à apprendre et $\\lambda$ un paramètre de régularisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mXrtZAIJGHh",
        "colab_type": "text"
      },
      "source": [
        "1) Montrer que la solution du problème de la régression à noyau avec la régularisation L2 est donnée par : \n",
        "$C = (K+\\lambda I)^{-1}Y$. \n",
        "\n",
        "Rappel : $\\forall A,B\\in\\mathbb{R}^{n\\times p}, \\displaystyle\\frac{\\partial \\langle A, B \\rangle}{\\partial B} = A$.\n",
        "\n",
        "Quelle est la complexité calculatoire de cette solution ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpqh49YzJ8ti",
        "colab_type": "text"
      },
      "source": [
        "*Réponse ici*\n",
        "\n",
        "\n",
        "*   ...\n",
        "*   ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrJrLhfJ9rG",
        "colab_type": "text"
      },
      "source": [
        "2) Implémenter l'algorithme calculant la solution de la régression à noyau avec régularisation L2 dans le cas où le noyau $k$ est le noyau Gaussien, c.a.d $k(x_i, x_j) = \\exp(-\\gamma ||x_i-x_j||^2)$ où $\\gamma$ un hyperparamètre de la méthode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP7eFCyELhLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kt_regression(data, target, gamma):\n",
        "    return ols_regression(data, target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc9jyVWfL6Om",
        "colab_type": "text"
      },
      "source": [
        "## Partie 3 : comparaison des deux méthodes et d'une méthode de réference simple\n",
        "\n",
        "On s'intéresse maintenant à comparer les performances de ces deux méthodes sur la prédiction de la moitié inférieure des images `digits` à partir de la moitié supérieure. Ces performances seront aussi comparées à celles obtenues par la régression multivariée par moindres carrés qui sera considérée comme \"baseline\" (méthode de réference)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spP3RKe_M-Bj",
        "colab_type": "text"
      },
      "source": [
        "1) Ecrire le code permettant :\n",
        "* de séparer les données en des données d'apprentissage et de test,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_cm9bdvNgD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.3,\n",
        "                                                random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idi4f_42LOgO",
        "colab_type": "text"
      },
      "source": [
        "* de sélectionner les hyperparamètres des algorithmes d'apprentissage sur l'échantillon d'apprentissage par validation croisée,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wOT2k-PLPzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# à noter que la solution proposée ne boucle par pour plusieurs sous-parties du\n",
        "# jeu de données en apprentissage, ce serait trop long\n",
        "\n",
        "ranks = range(1, 21)\n",
        "gammas = [0.1, 0.01, 0.001, 0.0001]\n",
        "\n",
        "# initialize classifiers\n",
        "names = ['lr', 'kt']\n",
        "results = []\n",
        "ranks_res = []\n",
        "gammas_res = []\n",
        "\n",
        "# train classifiers while saving coefficients and scores\n",
        "for name in names:\n",
        "    result = []\n",
        "    # for low rank\n",
        "    if name is 'lr':\n",
        "        for rank in ranks:\n",
        "            weights = lr_regression(Xtrain, ytrain, rank)\n",
        "            score = np.linalg.norm(ytrain - (Xtrain @ weights))\n",
        "            result.append(score)\n",
        "            ranks_res.append(rank)\n",
        "        results.append(result)\n",
        "    \n",
        "    # for kt\n",
        "    if name is 'kt':\n",
        "        for gamma in gammas:\n",
        "            weights = kt_regression(Xtrain, ytrain, rank)\n",
        "            score = np.linalg.norm(ytrain - (Xtrain @ weights))\n",
        "            result.append(score)\n",
        "            gammas_res.append(gamma)\n",
        "        results.append(result)\n",
        "\n",
        "results = np.array(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WXh0Q73LeLR",
        "colab_type": "text"
      },
      "source": [
        "* d'afficher les scores de trois algorithmes evalués sur l'échantillon test,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFpdduW4LdaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "be3827ab-9dce-4c1f-ce9e-d3b288955803"
      },
      "source": [
        "ols_weights = ols_regression(Xtest, ytest)\n",
        "ols_score = np.linalg.norm(ytest - (Xtest @ ols_weights))\n",
        "print(f'OLS test score : {ols_score}')\n",
        "\n",
        "BEST_PARAMETER_LR = None\n",
        "BEST_PARAMETER_KT = None\n",
        "\n",
        "for name, result in zip(names, results):\n",
        "    if name is 'lr':\n",
        "        # find best train score and related parameter\n",
        "        best_score_idx = np.argmin(result)\n",
        "        BEST_PARAMETER_LR = ranks_res[best_score_idx]\n",
        "\n",
        "        print(BEST_PARAMETER_LR)\n",
        "\n",
        "        lr_weights = lr_regression(Xtest, ytest, BEST_PARAMETER_LR)\n",
        "        lr_score = np.linalg.norm(ytest - (Xtest @ lr_weights))\n",
        "        print(f'LR test score : {lr_score}')\n",
        "    \n",
        "    if name is 'kt':\n",
        "        # find best train score and related parameter\n",
        "        best_score_idx = np.argmin(result)\n",
        "        BEST_PARAMETER_KT = gammas_res[best_score_idx]\n",
        "\n",
        "        print(BEST_PARAMETER_KT)\n",
        "\n",
        "        kt_weights = kt_regression(Xtest, ytest, BEST_PARAMETER_KT)\n",
        "        kt_score = np.linalg.norm(ytest - (Xtest @ kt_weights))\n",
        "        print(f'KT test score : {kt_score}')"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OLS test score : 488.33339257164283\n",
            "20\n",
            "LR test score : 488.42456057270175\n",
            "0.1\n",
            "KT test score : 488.33339257164283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8cJ2Bu4RL9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c30e4cae-9a60-4557-e48c-d029a4d67846"
      },
      "source": [
        "# let's plot distances !\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            y=distances_ols,\n",
        "            mode='lines',\n",
        "            name='Ordinary Least Square regression'\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            y=distances_lr,\n",
        "            mode='lines',\n",
        "            name='Low Rank regression'\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"f61b1fad-16ca-4ffa-8756-49ead84eb08b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"f61b1fad-16ca-4ffa-8756-49ead84eb08b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'f61b1fad-16ca-4ffa-8756-49ead84eb08b',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"Ordinary Least Square regression\", \"type\": \"scatter\", \"y\": [888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292, 888.5343251702292]}, {\"mode\": \"lines\", \"name\": \"Low Rank regression\", \"type\": \"scatter\", \"y\": [1071.2513017365534, 1014.3806583429016, 976.2052474412627, 947.8549159400665, 929.9695160220966, 916.2830932292346, 906.8198380824724, 901.253742196683, 898.0700106442806, 895.1766897701223, 893.2145702660031, 891.9158905180907, 890.9444221559081, 890.2800337010393, 889.7727459322107, 889.3637613454725, 889.0771531721715, 888.9016157975799, 888.7821130427454]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f61b1fad-16ca-4ffa-8756-49ead84eb08b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNCp81fPLfye",
        "colab_type": "text"
      },
      "source": [
        "* d'afficher des images construites à partir de cinq données d'entrée de test choisies au hasard et cela pour les trois méthodes de régression testées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SItBFvVeLgHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_up_and_down(x, y):\n",
        "    return np.concatenate((x, y), axis=0)\n",
        "\n",
        "def show_random_predicted_images(images, n_images=5):\n",
        "    # choisir `n_images` au hasard\n",
        "    idx = np.random.choice(images.shape[0], n_images)\n",
        "    images_to_predict = images[idx]\n",
        "\n",
        "    for image in images_to_predict:\n",
        "        image = np.reshape(image, (IMG_LENGTH, IMG_LENGTH))\n",
        "        x, y = split_upper_down_parts_for_one_image(image)\n",
        "\n",
        "        # baseline\n",
        "        plt.subplot(1, 4, 1)\n",
        "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        plt.title('initiale')\n",
        "\n",
        "        # ols\n",
        "        y_ols = ols_regression(x, y)\n",
        "        y_ols = np.reshape(y_ols, (IMG_LENGTH, IMG_LENGTH))\n",
        "        image_ols = combine_up_and_down(x, y_ols)\n",
        "        plt.subplot(1, 4, 2)\n",
        "        plt.imshow(image_ols, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        plt.title('OLS')\n",
        "\n",
        "        # lr\n",
        "        y_lr = lr_regression(x, y, BEST_PARAMETER_LR)\n",
        "        y_lr = np.reshape(y_lr, (IMG_LENGTH, IMG_LENGTH))\n",
        "        image_lr = combine_up_and_down(x, y_lr)\n",
        "        plt.subplot(1, 4, 3)\n",
        "        plt.imshow(image_lr, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        plt.title('LR')\n",
        "\n",
        "        # kernel trick\n",
        "        y_kt = kt_regression(x, y, BEST_PARAMETER_KT)\n",
        "        y_kt = np.reshape(y_kt, (IMG_LENGTH, IMG_LENGTH))\n",
        "        image_kt = combine_up_and_down(x, y_kt)\n",
        "        plt.subplot(1, 4, 4)\n",
        "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        plt.title('kernel trick')\n",
        "\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RV8EjqcN_SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_random_predicted_images(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYdcS0p8NhZ9",
        "colab_type": "text"
      },
      "source": [
        "2) Commenter les résultats obtenus. Quel algorithme recommanderiez vous d'utiliser ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kao9WWNkNuSM",
        "colab_type": "text"
      },
      "source": [
        "*Réponse ici*\n",
        "\n",
        "* les résultats sont complètement contre-intuitifs, je m'attendais à ce que la régression de faible rang fonctionne mieux que OLS classique\n",
        "\n",
        "* pas d'implémentation de la méthode kernel trick"
      ]
    }
  ]
}